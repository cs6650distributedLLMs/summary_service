version: '3'

services:
  # API Service - Handles client requests
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "5001:5000"
    environment:
      - PORT=5000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=
    volumes:
      - ./app.py:/app/app.py
    depends_on:
      - redis
    restart: unless-stopped
  
  # Worker Service - Processes jobs from the queue
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=
      - GROKX_API_KEY=${GROKX_API_KEY}
      - GROKX_API_URL=https://api.x.ai/v1/chat/completions
      - POLLING_INTERVAL=5
    volumes:
      - ./worker.py:/app/worker.py
    depends_on:
      - redis
    restart: unless-stopped
    # You can scale this by setting replicas
    deploy:
      replicas: 2  # Start with 2 worker instances
  
  # Redis for status tracking
  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped

volumes:
  redis-data: